#pragma once

#include "Utilities/EnumFlags.h"
#include "JobTypes.h"

// TODO (scobi 4-jan-15): this should eventually go to Modules/Core/Threading/Jobs and be namespaced

struct Job;
typedef void JobFunc (void* userData);
typedef void JobForEachFunc (void* userData, unsigned index);

/*

// For a job system introduction overview including a video on a walk through of the job system please also see this.
// http://confluence.hq.unity3d.com/pages/viewpage.action?pageId=983147
// (Source Code customers: See UnitySourceDocumentation.pdf)



// JobScheduler system for OnDemand completion of jobs.
// Jobs are scheduled as a function pointer and T* jobData
// A variety of scheduling functions are offered below.

// SyncFence guarantees that the job & its dependencies is completed when SyncFence returns.
// Thus when all data that the job writes to are protected by SyncFence it is completely safe to access that data.

// After you schedule a job, you set the fence on all data that will be written by the job. And any code that reads or writes
// that data has to call SyncFence before accessing it.
// This way the behaviour appears deterministic & consistent with what happens in single threaded codepath,
// where each function is executed immediately.
// SyncFence can be called at any point, it can also be called from inside a job.
// (It is recommended to use ScheduleJobDepends over SyncFence inside of jobs for clarity & performance wherever possible)
//
// It is not necessary to call SyncFence on a scheduled job and you can call SyncFence as many times as you like.
// The JobScheduler will simply return immediately if the job has already been completed.
//
// It is allowed to copy a JobFence as much as you like. Copying a JobFence allocates no memory.
// For example we transfer a JobFence over the render thread command buffer to wait on animation / skin matrix extraction jobs
// when a mesh is skinned.
//
// A JobFence should be copied in all places where the output of a job is accessed.
// Before the data is accessed SyncFence should be called.

// The Job system is designed to process SyncFence jobs the as fast as possible.
// If the main thread calls SyncFence the main thread will perform the necessary jobs as well.
// First of all it will extract all necessary jobs (jobs associated to the fence & all dependencies) to the high priority stack.
// Thus all worker threads will reprioritize to work on those jobs instead. (As opposed to queue order)
// The thread calling SyncFence will first try to pick up jobs associated to the fence & dependencies, if worker threads have already
// picked up all these jobs, then that thread will pick up any job that is marked kGuaranteeNoSyncFence.


//// ----  PSEUDO CODE EXAMPLE - simple job scheduling ----
JobFence myDataFence;
ScheduleJob (myDataFence, MyJobFunction, myJobData);
... Do some work while the job is executing

// Ensure that the job has completed.
SyncFence(myDataFence);
... Do some work that accesses the data that the job produces.


//// ----  PSEUDO CODE EXAMPLE - job scheduling with dependencies----
JobFence firstJob;
ScheduleJob (firstJob, MyJobFunction1, myJobData);

// Schedule a job that will only start once firstJob has completed.
// (You can have arbitrarily deep dependencies and also depend on foreach jobs)
JobFence secondJob;
ScheduleJobDepends (secondJob, MyJobFunction2, myJobData, firstJob);

... Do some work while the job is executing

// Ensure that the first job has completed.
SyncFence(firstJob);
... access data generated by the first job

// Ensure that the second job has completed.
// (Please note that it is not necessary to call SyncFence (firstJob); as above if you don't need to access the output data earlier.
// due to the ScheduleJobDepends the first job is already implicitly known to be completed)
SyncFence(secondJob);
... Do some work that accesses the data that the second job produces.

*/

/// By default a job will be placed on the queue. The jobs will be executed in order.
/// When a job group (e.g. ScheduleJobForEach) is popped from the queue, it will be placed on the high priority stack.
/// All jobs that are on the stack will be processed first. When the stack is empty, more items will be taken from the queue to the stack.
///
// Implementation note: This enum must be kept in sync with JobQueue.h
enum JobPriority
{
	// Places a job on the queue. In order execution. This is the recommended approach.
	kNormalJobPriority = 0,
	
	/// Skip ahead of the queue and execute the job directly on the stack.
	/// Don't over-use otherwise it defeats the purpose. Only use it if you have lots of normal jobs
	/// and few jobs that you know you will schedule late but wait on immediately.
	kHighJobPriority = 1 << 0,

	/// Use this bitmask when you can 100% guarantee that a job does not use SyncFence.
	/// This allows the job system to use the job while waiting for other dependencies.
	/// It can increase concurrencies while waiting for jobs.
	///
	/// This can have a significant impact on performance.
	/// but if used incorrectly (SyncFence is actually called when kGuaranteeNoSyncFence is set) then it will deadlock.
	/// SA: JobQueue for more details if you are curious on the implementation details.
	kGuaranteeNoSyncFence = 1 << 1,

	/// Schedule the Job for execution in the main thread in the update loop
	kExecuteOnMainThread = 1 << 2,
};
ENUM_FLAGS(JobPriority);


// Waits for a job and all it's dependencies to complete. See above for more information.
// This mutates fence.group = NULL to make the next SyncFence call early out.
inline void SyncFence(JobFence& fence);
// This version does not clear fence.group. Thus multiple jobs may call SyncFenceNoClear against the same JobFence..
void SyncFenceNoClear(const JobFence& fence);

// A single job will be executed on any worker thread.
template<typename T>
inline void ScheduleJob(JobFence& fence, void jobFunc(T*), T* jobData, JobPriority priority = kNormalJobPriority);

// A single job will be executed on any worker thread.
// Jobs in dependsOn will be executed before this job executes.
// You can have arbitrarily deep job dependencies.
// The normal usage is to pass another job that was just scheduled.
// However for robustness you can also pass a job has already been completed / never been scheduled / already completed.
// ScheduleJob & ForEach & DifferentJobsConcurrent are of course all compatible with each other as dependencies.
template<typename T>
inline void ScheduleJobDepends(JobFence& fence, void jobFunc(T*), T* jobData, const JobFence& dependsOn, JobPriority priority = kNormalJobPriority);

// The array of jobs (each job has a different jobFunc and jobData) will be executed in any order on any worker thread.
// All jobs are associated to a single fence, thus SyncFence will wait for all jobs in the array to complete.
void ScheduleDifferentJobsConcurrent (JobFence& fence, const Job* jobs, int jobCount, JobPriority priority = kNormalJobPriority);
void ScheduleDifferentJobsConcurrentDepends (JobFence& fence, const Job* jobs, int jobCount, const JobFence& dependsOn, JobPriority priority = kNormalJobPriority);

// /concurrentJobFunc/ will be executed concurrently in any order on any worker thread.
// The index of the iteration is passed to the /concurrentJobFunc/ function.
// /combineJobFunc/ will be executed on any thread after all for each jobs jobs have been executed.
template<typename T>
inline void ScheduleJobForEach(JobFence& fence, void concurrentJobFunc(T*, unsigned), T* jobData, int iterationCount, void combineJobFunc(T*), JobPriority priority = kNormalJobPriority);
template<typename T>
inline void ScheduleJobForEach(JobFence& fence, void concurrentJobFunc(T*, unsigned), T* jobData, int iterationCount, JobPriority priority = kNormalJobPriority);
template<typename T>
inline void ScheduleJobForEachDepends(JobFence& fence, void concurrentJobFunc(T*, unsigned), T* jobData, int iterationCount, const JobFence& dependsOn, void combineJobFunc(T*), JobPriority priority = kNormalJobPriority);
template<typename T>
inline void ScheduleJobForEachDepends(JobFence& fence, void concurrentJobFunc(T*, unsigned), T* jobData, int iterationCount, const JobFence& dependsOn, JobPriority priority = kNormalJobPriority);
bool ExecuteOneJobInMainThread();

/*

//// *** A best practice example of how to use ScheduleJobForEach to process an array of data split over multiple jobs ***
//// *** IMPORTANT: The structure used to pass data to the job MUST have the 'JobData' suffix. ***
//// *** IMPORTANT: The job functions must have the 'Job' suffix. ***

PROFILER_INFORMATION(gCopyFloatJob, "CopyFloats", kProfilerRender);
PROFILER_INFORMATION(gCopyFloatCombineJob, "CopyFloatsCombine", kProfilerRender);

struct CopyFloatJobData
{
	BlockRange		blocks[kMaximumBlockRangeCount];
	const float*	input;
	float*			output;
};

static void CopyFloatJob (CopyFloatJobData* jobData, unsigned index)
{
	// Jobs should always have a profiler block around the entire job
	PROFILER_AUTO (gCopyFloatJob, NULL);

	int begin = jobData->blocks[index].startIndex;
	int end = begin + jobData->blocks[index].rangeSize;
	
	for (int i = begin; i != end; i++ )
		jobData->output[i] = jobData->input[i];
}

static void CopyFloatCombineJob (CopyFloatJobData* jobData)
{
	// Jobs should always have a profiler block around the entire job
	PROFILER_AUTO (gCopyFloatCombineJob, NULL);

	// ... Do any processing that can only be done when all foreach jobs have completed processing.

	// Destroy the job data struct
	UNITY_DELETE(jobData, kMemTempJobAlloc);
}


void CopyFloats (JobFence& fence, const float* inputs, const float* outputs, unsigned size)
{
	CopyFloatJobData& jobData = *UNITY_NEW (CopyFloatJobData, kMemTempJobAlloc);

	// Executing a separate job has overhead (function call overhead, atomic operation over head etc.)
	// thus we want to ensure that we perform some reasonable amount of work that greatly exceeds the overhead.
	// As a general guideline jobs should aim to take longer than 0.05ms
	// ConfigureBlockRangesWithMinIndicesPerJob automatically takes into account the amount of worker threads available.
	const int minIterationsPerJob = 1024;
	int jobCount = ConfigureBlockRangesWithMinIndicesPerJob (jobData.blocks, size, minIterationsPerJob);

	// CopyFloatJob will be called on worker threads concurrently in any order.
	// when the last CopyFloatJob completes, CopyFloatCombineJob is called.
	ScheduleJobForEach (fence, CopyFloatJob, &jobData, jobCount, CopyFloatCombineJob);
}

void ComputeSyncAndAccess ()
{
	JobFence fence;
	float inputs[] = { 0, 1, 2};
	float outputs[] = { 0, 1, 2};
	CopyFloats (fence, inputs, outputs, 3);
	// ... Perform some other work (We want to avoid calling SyncFence right after scheduling jobs, wherever that is feasible)
	// In the best case we would schedule a job at the beginning of the frame and SyncFence it only at the end of the frame.
	// Generally try to call SyncFence as late as possible. It is a good idea to design execution order with this in mind.
	SyncFence (fence);

	// outputs is now guaranteed to have the computed data.
	printf("%f\n", outputs[0]);
}
*/

// Sometimes fenced data is known to not be accessed after a certain point.
// It is not necessary to wait for it, and we will avoid the assert in the JobFence destructor.

// For example See SkinMeshInfo.writePoseMatricesFence
// SkinMeshInfo is passed via the render thread command queue to another thread
// The SkinMeshInfo on the main thread can safely be destructed without waiting.
// Because SkinMeshInfo on the render thread will now own the data which is written to from a job.
// We can safely call ClearFenceWithoutSync on the main thread and SyncFence is invoked by code on the render thread which will
// wait for the data to job to complete before the Matrix4x4 array of poses is destroyed or used.
void ClearFenceWithoutSync (JobFence& fence);

/// Returns true if the JobFence has completed
bool IsFenceDone (const JobFence& fence);

//	Ensure a fence has been synced. Typical use : Assert (FenceHasBeenSynced(fence))
inline bool FenceHasBeenSynced (const JobFence& fence);


struct Job
{
	JobFunc* jobFunction;
	void* userData;

	template<typename T>
	Job(void inJobFunc(T*), T* inJobData)
		: jobFunction(reinterpret_cast<JobFunc*>(inJobFunc)), userData(inJobData) { }
};


// INLINES


inline void SyncFence (JobFence& fence)
{
	if (fence.group.info == NULL)
		return;

	void CompleteFenceInternal(JobFence& fence);
	CompleteFenceInternal(fence);
}

inline bool FenceHasBeenSynced (const JobFence& fence)
{
	return fence.group.info == NULL;
}

template<typename T>
inline void ScheduleJob(JobFence& fence, void jobFunc(T*), T* jobData, JobPriority priority)
{
	void ScheduleJobInternal(JobFence& fence, JobFunc* jobFunc, void* userData, JobPriority priority);
	ScheduleJobInternal(fence, reinterpret_cast<JobFunc*>(jobFunc), jobData, priority);
}

template<typename T>
inline void ScheduleJobDepends(JobFence& fence, void jobFunc(T*), T* jobData, const JobFence& dependsOn, JobPriority priority)
{
	void ScheduleJobDependsInternal(JobFence& fence, JobFunc* jobFunc, void* userData, const JobFence& dependsOn, JobPriority priority);
	ScheduleJobDependsInternal(fence, reinterpret_cast<JobFunc*>(jobFunc), jobData, dependsOn, priority);
}

template<typename T>
inline void ScheduleJobForEach(JobFence& fence, void concurrentJobFunc(T*, unsigned), T* jobData, int iterationCount, void combineJobFunc(T*), JobPriority priority)
{
	void ScheduleJobForEachInternal(JobFence& fence, JobForEachFunc* concurrentJobFunc, void* userData, int iterationCount, JobFunc* combineJobFunc, JobPriority priority);
	ScheduleJobForEachInternal(fence, reinterpret_cast<JobForEachFunc*>(concurrentJobFunc), jobData, iterationCount, reinterpret_cast<JobFunc*>(combineJobFunc), priority);
}

template<typename T>
inline void ScheduleJobForEach(JobFence& fence, void concurrentJobFunc(T*, unsigned), T* jobData, int iterationCount, JobPriority priority)
{
	void ScheduleJobForEachInternal(JobFence& fence, JobForEachFunc* concurrentJobFunc, void* userData, int iterationCount, JobFunc* combineJobFunc, JobPriority priority);
	ScheduleJobForEachInternal(fence, reinterpret_cast<JobForEachFunc*>(concurrentJobFunc), jobData, iterationCount, NULL, priority);
}

template<typename T>
inline void ScheduleJobForEachDepends(JobFence& fence, void concurrentJobFunc(T*, unsigned), T* jobData, int iterationCount, const JobFence& dependsOn, void combineJobFunc(T*), JobPriority priority)
{
	void ScheduleJobForEachDependsInternal(JobFence& fence, JobForEachFunc* concurrentJobFunc, void* userData, int iterationCount, const JobFence& dependsOn, JobFunc* combineJobFunc, JobPriority priority);
	ScheduleJobForEachDependsInternal(fence, reinterpret_cast<JobForEachFunc*>(concurrentJobFunc), jobData, iterationCount, dependsOn, reinterpret_cast<JobFunc*>(combineJobFunc), priority);
}

template<typename T>
inline void ScheduleJobForEachDepends(JobFence& fence, void concurrentJobFunc(T*, unsigned), T* jobData, int iterationCount, const JobFence& dependsOn, JobPriority priority)
{
	void ScheduleJobForEachDependsInternal(JobFence& fence, JobForEachFunc* concurrentJobFunc, void* userData, int iterationCount, const JobFence& dependsOn, JobFunc* combineJobFunc, JobPriority priority);
	ScheduleJobForEachDependsInternal(fence, reinterpret_cast<JobForEachFunc*>(concurrentJobFunc), jobData, iterationCount, dependsOn, NULL, priority);
}
